{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f843a7-7632-4ebd-b57a-e45b6d48b836",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of precision and recall in the context of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70117f87-8993-4ea6-b213-7c9f21743f99",
   "metadata": {},
   "source": [
    "Precision:\n",
    "Precision is a measure that focuses on the accuracy of positive predictions made by a classification model. It's the ratio of true positive predictions to the total number of positive predictions (true positives + false positives). In other words, precision tells us how many of the instances predicted as positive by the model are actually true positives.\n",
    "Mathematically, precision is calculated as:\n",
    "\n",
    "Precision = True Positive / (True Positives + False Positives)\n",
    "​\n",
    "\n",
    "Recall (Sensitivity or True Positive Rate):\n",
    "Recall is a measure that focuses on the model's ability to identify all relevant instances of a certain class within the dataset. It's the ratio of true positive predictions to the total number of actual positive instances (true positives + false negatives). In other words, recall tells us how well the model is capturing all the positive instances.\n",
    "\n",
    "Recall = True Positive / (TP + FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc4c13b-ffea-4630-9ef8-306eeaf3c583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b91160-e483-4ed3-be92-2c7018602eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d1d333c-70f3-4e17-8bd8-6f9c9fa8c829",
   "metadata": {},
   "source": [
    "Q2. What is the F1 score and how is it calculated? How is it different from precision and recall?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0813bb-2145-4d36-b298-26499e7820a6",
   "metadata": {},
   "source": [
    "The F1 score is a single metric that combines both precision and recall to provide a balanced measure of a classification model's performance. It is particularly useful when there is an imbalance between classes or when both false positives and false negatives need to be considered in a meaningful way.\n",
    "\n",
    "The F1 score is calculated as the harmonic mean of precision and recall:\n",
    "\n",
    "f1_scored = 2 X {(precision x Recall) / (precision + recall)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a67491-1781-4b46-8d34-2071840b2cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc31bcbc-7177-4d42-83e0-6ad7f1c80529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4114185-e675-4b64-81ce-ce696c058414",
   "metadata": {},
   "source": [
    "Q3. What is ROC and AUC, and how are they used to evaluate the performance of classification models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2cc481-afc8-4aea-9eff-93ccfbe3ba40",
   "metadata": {},
   "source": [
    "ROC Curve:\n",
    "The ROC curve is a graphical representation of the performance of a classification model across various thresholds for making binary decisions. It plots the True Positive Rate (recall or sensitivity) against the False Positive Rate (1 - specificity) as the discrimination threshold is varied.\n",
    "\n",
    "True Positive Rate (TPR): This is the same as recall. It's the ratio of true positive predictions to the total number of actual positive instances.\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "True Positives\n",
    "True Positives\n",
    "+\n",
    "False Negatives\n",
    "TPR= \n",
    "True Positives+False Negatives\n",
    "True Positives\n",
    "​\n",
    " \n",
    "\n",
    "False Positive Rate (FPR): This is the ratio of false positive predictions to the total number of actual negative instances.\n",
    "�\n",
    "�\n",
    "�\n",
    "=\n",
    "False Positives\n",
    "False Positives\n",
    "+\n",
    "True Negatives\n",
    "FPR= \n",
    "False Positives+True Negatives\n",
    "False Positives\n",
    "​\n",
    " \n",
    "\n",
    "The ROC curve provides a visual way to assess how well a model is distinguishing between the two classes. A model with better performance will have an ROC curve that is closer to the upper-left corner of the plot.\n",
    "\n",
    "AUC (Area Under the Curve):\n",
    "The AUC is a scalar value that quantifies the overall performance of a classification model using the ROC curve. It represents the area under the ROC curve and ranges from 0 to 1. The higher the AUC, the better the model's ability to distinguish between positive and negative instances.\n",
    "\n",
    "An AUC of 0.5 indicates that the model's predictions are as good as random guessing.\n",
    "An AUC above 0.5 suggests that the model is better than random guessing.\n",
    "An AUC of 1 indicates that the model perfectly distinguishes between the classes.\n",
    "In general, a higher AUC suggests a better model, but the interpretation might vary depending on the specific problem. AUC is particularly useful when dealing with imbalanced datasets or when you want to compare the performance of different models in a consistent manner.\n",
    "\n",
    "Using ROC and AUC for Evaluation:\n",
    "ROC curves and AUC are valuable tools for comparing and selecting models based on their classification performance. They provide insights into how well a model balances the trade-off between true positives and false positives across different decision thresholds. When choosing a model, you might prefer the one with a higher AUC if the problem requires a good trade-off between sensitivity and specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273dff3-97f7-459c-815d-c7258a0caa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f534a-bae1-428f-89fd-5cd4cbdef28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "003bdaa9-048e-4efe-b9fa-392d3f5efc97",
   "metadata": {},
   "source": [
    "Q4. How do you choose the best metric to evaluate the performance of a classification model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18275735-c667-4133-be4f-14ecc617dbc6",
   "metadata": {},
   "source": [
    "Understand Your Problem and Goals:\n",
    "\n",
    "What is the nature of your classification problem? Is it binary or multi-class?\n",
    "What are the consequences of false positives and false negatives in your specific domain? Are they equally important, or does one type of error carry a higher cost?\n",
    "Are you more concerned about identifying all positive instances (high recall) or ensuring that the identified positives are accurate (high precision)?\n",
    "Consider the Nature of the Data:\n",
    "\n",
    "Is your dataset imbalanced, where one class is much more prevalent than the other?\n",
    "Are there any specific challenges related to class distribution or data quality?\n",
    "Select Appropriate Metrics:\n",
    "Based on your problem and goals, consider the following metrics:\n",
    "\n",
    "Accuracy: Generally useful for balanced datasets and when the cost of false positives and false negatives is roughly equal. Not suitable for imbalanced datasets.\n",
    "\n",
    "Precision and Recall: Valuable when there is a cost imbalance between false positives and false negatives. You can prioritize one over the other depending on your goals.\n",
    "\n",
    "F1 Score: Useful when you want to balance precision and recall, especially in imbalanced datasets.\n",
    "\n",
    "ROC Curve and AUC: Beneficial when evaluating the trade-off between true positives and false positives across different thresholds. Particularly helpful when class distribution is imbalanced.\n",
    "\n",
    "Specificity: The ratio of true negatives to the total number of actual negatives. Relevant when avoiding false positives is critical.\n",
    "\n",
    "Balanced Accuracy: Suitable for imbalanced datasets; it takes the average of recall for each class, which helps account for class imbalance.\n",
    "\n",
    "Domain Knowledge and Stakeholder Input:\n",
    "Consult domain experts and stakeholders to gain insights into the real-world implications of classification errors. Their input can help you understand the costs associated with different types of mistakes.\n",
    "\n",
    "Experiment and Validation:\n",
    "Evaluate your model using multiple metrics and validation techniques (e.g., cross-validation). This helps you understand the model's behavior under different conditions and ensures that the chosen metric aligns with your goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7012ec2-1c86-4bd3-a407-d67241b68e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a8b1a-b319-4903-8794-24274c56b25a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c315ccc8-43ce-45a4-8793-59cb6157ab25",
   "metadata": {},
   "source": [
    "Q5. Explain how logistic regression can be used for multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192c4e1-ffba-48dc-8e95-9aa0d82fecf5",
   "metadata": {},
   "source": [
    "Data Preparation:\n",
    "\n",
    "Your training dataset should have samples labeled with multiple classes.\n",
    "Each class needs to be assigned as the positive class once and the rest of the classes as the negative class for that specific binary classification problem.\n",
    "Model Training:\n",
    "\n",
    "For each class, train a separate binary logistic regression model using the labeled data.\n",
    "In each model, the positive class corresponds to the class you're trying to predict, and the negative class corresponds to all other classes.\n",
    "Prediction:\n",
    "\n",
    "To make a prediction for a new instance, pass it through all the binary classifiers.\n",
    "Each classifier will produce a probability score indicating the likelihood of the instance belonging to the corresponding class.\n",
    "The class with the highest probability score is predicted as the final class for the instance.\n",
    "Advantages of One-vs-All:\n",
    "\n",
    "One-vs-All is easy to implement and works well with most binary classifiers, including logistic regression.\n",
    "It's especially useful when the underlying binary classifier is efficient and performs well on its own.\n",
    "Limitations of One-vs-All:\n",
    "\n",
    "One-vs-All can potentially lead to imbalanced training sets, especially if the classes are imbalanced to begin with.\n",
    "The classifiers are trained independently, so there might not be direct optimization of a multiclass objective.\n",
    "Decision boundaries between classes might not be well-calibrated in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d099da4-7f1a-49ae-b7c0-03ae5bb7abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a LogisticRegression model with 'multinomial' solver for multiclass problems\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5506aaf2-d45b-4ef9-a866-655f71a13c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8947fcde-402b-41ea-9402-83b37ceccf1c",
   "metadata": {},
   "source": [
    "Q6. Describe the steps involved in an end-to-end project for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915b0226-380e-4e4c-a1ab-f9da95cb8322",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 0. 1. 0. 0. 2. 1. 0. 0. 0. 2. 1. 1. 0. 0. 1. 2. 2. 1. 2. 1. 2. 1. 0.\n 2. 1. 0. 0. 0. 1. 2. 0. 0. 0. 1. 0. 1. 2. 0. 1. 2. 0. 2. 2. 1. 1. 2. 1.\n 0. 1. 2. 0. 0. 1. 1. 0. 2. 0. 0. 1. 1. 2. 1. 2. 2. 1. 0. 0. 2. 2. 0. 0.\n 0. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 2. 0. 2. 1. 2. 1. 1. 1. 0. 1. 1. 0. 1.\n 2. 2. 0. 1. 2. 2. 0. 2. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 0. 1. 2. 0. 1. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m     20\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m---> 21\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:848\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:824\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 824\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:861\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m    860\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 861\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 900\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    903\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    905\u001b[0m         )\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    909\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 0. 1. 0. 0. 2. 1. 0. 0. 0. 2. 1. 1. 0. 0. 1. 2. 2. 1. 2. 1. 2. 1. 0.\n 2. 1. 0. 0. 0. 1. 2. 0. 0. 0. 1. 0. 1. 2. 0. 1. 2. 0. 2. 2. 1. 1. 2. 1.\n 0. 1. 2. 0. 0. 1. 1. 0. 2. 0. 0. 1. 1. 2. 1. 2. 2. 1. 0. 0. 2. 2. 0. 0.\n 0. 1. 2. 0. 2. 2. 0. 1. 1. 2. 1. 2. 0. 2. 1. 2. 1. 1. 1. 0. 1. 1. 0. 1.\n 2. 2. 0. 1. 2. 2. 0. 2. 0. 1. 2. 2. 1. 2. 1. 1. 2. 2. 0. 1. 2. 0. 1. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "\n",
    "print('Accuracy:' , accuracy)\n",
    "print('Classification Report:\\n', report)\n",
    "\n",
    "coefficients = model.coef_\n",
    "plt.figure(figsize=(12,6))\n",
    "plg.bar(range(len(class_names)), coefficients[0], tick_label=class_names)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bdd35d-e49c-4bc2-b2f8-ee933fbcfbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c68f2-1fb6-4bb5-8414-eba807fdb153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b127fb49-44fe-4f4d-bca6-8a43b8c4c1ca",
   "metadata": {},
   "source": [
    "Q7. What is model deployment and why is it important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67dc210-8034-401b-bf32-db9c470bdf7e",
   "metadata": {},
   "source": [
    "Model deployment refers to the process of making a machine learning model available for use in real-world applications. It involves taking a trained model that has been developed and tested during the development phase and integrating it into a production environment where it can provide predictions or insights for new, unseen data. Model deployment is a crucial step in the lifecycle of a machine learning project, and its importance lies in the following aspects:\n",
    "\n",
    "Real-World Application:\n",
    "Deploying a model allows it to be used in practical scenarios where it can provide valuable predictions or decisions to end-users or systems. The model's insights can contribute to informed decision-making and improved processes.\n",
    "\n",
    "Automation and Efficiency:\n",
    "By deploying a model, manual decision-making processes can be automated. This leads to increased efficiency, reduced human effort, and faster decision-making, especially when dealing with large volumes of data.\n",
    "\n",
    "Scalability:\n",
    "Deployed models can handle a high volume of data and requests, making them suitable for applications that require processing a large number of instances in a short time.\n",
    "\n",
    "Consistency:\n",
    "Deployed models ensure consistent and standardized decision-making, as they follow the same rules and guidelines for every input.\n",
    "\n",
    "Access to Insights:\n",
    "Model deployment enables users and systems to gain insights from the model's predictions or classifications. These insights can help in understanding trends, patterns, and anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e4bc92-dd4e-4c8c-a4e1-d9a9982a7016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fac121-b51b-4ff1-9702-2f8dc9ab3ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "529852f4-4307-4105-8bfa-fc8dd572d171",
   "metadata": {},
   "source": [
    "Q8. Explain how multi-cloud platforms are used for model deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf51c7c-782d-49e0-93c9-f63166634b6c",
   "metadata": {},
   "source": [
    "Multi-cloud platforms refer to the practice of using services and resources from multiple cloud providers, such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and others, to build and deploy applications and services. Multi-cloud strategies offer various benefits, including reducing vendor lock-in, improving reliability, and accessing unique features from different providers. When it comes to model deployment, multi-cloud platforms can be utilized to ensure flexibility, redundancy, and optimal performance. Here's how they are used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afbab9-12dc-46ad-95f7-766288d7b8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa07b1-ab16-465a-a383-b3afb6a5d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b383173e-9512-41b5-8f81-693e2e7ad25d",
   "metadata": {},
   "source": [
    "Q9. Discuss the benefits and challenges of deploying machine learning models in a multi-cloud\n",
    "environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30fdca-1da8-401c-b596-0033f74070b4",
   "metadata": {},
   "source": [
    "Deploying machine learning models in a multi-cloud environment comes with both benefits and challenges. Let's explore each of these aspects:\n",
    "\n",
    "Benefits:\n",
    "\n",
    "Vendor Independence and Avoiding Lock-In:\n",
    "Deploying across multiple cloud providers reduces the risk of vendor lock-in. Organizations can choose the best services from different providers without being restricted to a single ecosystem.\n",
    "\n",
    "Redundancy and High Availability:\n",
    "Multi-cloud deployment enhances redundancy and high availability. If one provider experiences downtime, models and applications can continue to operate on other platforms.\n",
    "\n",
    "Optimal Resource Allocation:\n",
    "Different cloud providers offer specialized services. Organizations can select the most suitable platform for different components of their applications, optimizing performance and efficiency.\n",
    "\n",
    "Geographic Reach and Performance:\n",
    "Multi-cloud deployment allows organizations to serve users from various geographic locations using data centers from different providers, improving performance and minimizing latency.\n",
    "\n",
    "Cost Optimization:\n",
    "Organizations can choose providers based on cost-effectiveness for specific services. This flexibility helps in managing budgets and avoiding unnecessary expenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d466c35-001f-4978-be7d-27bd660855b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df04b9-9170-40ba-8e68-e589aebe40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc929e-8dfd-4184-ab26-5e197d0f626a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
